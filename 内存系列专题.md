# 内存系列专题

## 1 内存空间

内存空间包括

- 内存
- 寄存器

CPU访问内存，如果存在MMU，则CPU发出访问虚拟地址请求，MMU将虚拟地址转换为物理地址。CPU与程序员的视角是一样的，都只能看到虚拟地址。比如一个全局变量的地址是1G，那么这个1G就是虚拟地址。

## 2 Linux内核熔断原理

基于时间的旁路攻击

## 3 内存映射

### 3.1 高端内存与低端内存

内核线性映射区的物理内存包含（可线性映射的物理内存即是低端内存，其余为高端内存）

- ZONE_DMA
- ZONE_NORMAL

物理地址0到896M映射到虚拟地址3G到4G空间，然后把剩余没有映射的物理内存称为HIGH memory，HIGH memory也不是浪费掉了，只是内核一般不访问HIGH memory。内核也可以访问HIGH memory，只是访问之前需要先做映射。不像NORMAL memory一样，NORMAL memory开机就映射好了，访问使直接通过虚拟地址加偏移就可以得到物理地址。

Linux内核中virt_to_phys与phys_to_vir两个虚拟地址与物理地址转换的宏函数只针对线性映射区，因为这两个宏函数只是简单的将虚拟地址减去一个偏移即可得到物理地址。

不是线性映射的物理内存称为

- ZONE_HIGH

### 3.2 低端内存中的ZONE_DMA

ZONE_DMA存在的原因是因为硬件缺陷，内存可能被两个器件访问，一个是CPU，一个DMA引擎（包括GPU）。CPU访问内存，经过MMU访问具体物理内存。DMA访问内存，绝大部分DMA不带MMU，直接访问内存，不需要CPU帮忙，比如网卡收到报文，直接通过DMA写到物理内存，这样CPU就可以空闲下来干别的事情。DMA最大的好处就是将CPU空闲下来做别的事情，但是DMA不能使访问变快，快慢是由总线频率决定的。

DMA可以直接访问内存，但是由于某些DMA存在缺陷，只能访问16M以下的内存。所以必须申请内存分配16M以下的物理内存，16M以上的物理内存访问不了。所以Linux就对ZONE_NORMAL中的一段内存砍一刀，分出一个ZONE_DMA。当有缺陷的DMA引擎申请内存时，就会带一个特殊的标记GFP_DMA，然后Linux就从ZONE_DMA区给DMA申请物理内存。但是ZONE_DMA内存谁都可以申请 ，ZONE_DMA内存表示有缺陷的DMA申请的内存一定是从这里申请的。对于没有缺陷的DMA，可以访问所有地方的内存，那么随便申请一块内存就可以使用。所以，**用作DMA的内存不一定来自ZONE_DMA，ZONE_DMA的内存也不一定给DMA使用。**

所以，如果系统上的DMA没有任何缺陷，那么就不会在ZONE_NORMAL中划分ZONE_DMA，整个系统也就只有ZONE_NORMAL和ZONE_HIGH。

### 3.3 BUDDY算法管理物理内存

buddy算法直面物理内存，buddy算法以页为单位管理物理内存，且分ZONE分区管理，物理内存不可能跨ZONE区分配。任何一个正整数都可以分成2的N次方的和，所以buddy管理的物理内存链表就会不断的拆分合并。

理解buddy算法后，就可以理解`cat /proc/buddyinfo`。这里的信息以ZONE为区域，分别展示每个ZONE分区2的N次方物理内存页可用的部分。

### 3.4 CMA解决BUDDY算法的缺陷

buddy算法有一个缺陷，经过不算的分配内存，最后可能出现剩余物理内存很大，但是连续的物理内存已经很小了。

谁会申请连续的物理内存呢？DMA会，应用程序不会，应用程序直面虚拟内存，经过MMU后，可以将不连续的物理内存映射到连续的虚拟内存上，所以应用程序感知不到连续的物理内存，只感知到连续的虚拟内存。DMA需要连续的物理内存，早期为了解决连续物理内存的需求，采用预留内存方法，比如1G内存，实际可用内存只有800多兆，其余内存都是预留内存，平时不用也要预留，在比如电脑的集成显卡，电脑会预留一部分内存给集成显卡。

后来三星公司提出了CMA机制（连续物理内存分配）。其原理就是将上面预留的内存区域在平时不用时给可movable的内存页面使用。什么是可movable的内存呢？比如应用程序的堆内存，应用程序无感知物理内存，当DMA需要使用连续物理内存时，Linux内核会寻找其他空闲物理内存，将预留内存中被占用的内存移到其他不连续的内存中，然后修改应用程序的映射页表，这样应用程序就无感知物理内存的变动，同时DMA也可申请连续物理内存。

## 4 内存分配释放

- slab kmalloc/kfree /proc/slabinfo slabtop
- 用户空间malloc/free与内核之间的关系
- mallopt
- vmalloc
- 内存耗尽（OOM oom_score oom_adj）
- android进程生命周期与OOM



### 4.1 slab算法以及延伸接口

所有的内存申请都是从buddy中申请的，但是buddy管理的物理内存粒度太大，最小单位为4K，而我们常常需要申请小内存，为此，Linux引入slab算法。内核态的kmalloc与kfree直接从slab中获取内存，用户态的malloc与free从libc中获取内存。

#### 4.1.1 slab原理：

- kmalloc需要申请32字节内存
- slab从buddy中申请1页内存，然后将这一页平分成多个32字节内存，每个slab中都是有等份的，32字节等份的slab里面只有32字节对象，64字节等份slab只有64字节对象，不会存在slab又给32字节，又给64字节。

可以通过`cat /proc/slabinfo`查看slab分配的情况。Linux中的slab申请内存分为两种：

- 常用数据结构
- kmalloc常见小内存

在`cat /proc/meminfo`中也可以看到slab中的一些信息：

- Slab表示总的slab管理内存有多大
- SReclaimable表示可回收的slab内存

IO中有一些iNode的entry的内存也是通过slab申请的，这部分内存是可以回收的。

- SUnreclaim表示不可回收的slab内存

一般kmalloc申请的内存是不可回收的。

slab也是一个内存泄漏的源头，如果内核空间查看`/proc/meminfo`中slab使用总的内存越来越大，然后`/proc/slabinfo`看看哪个slab粒度的内存越来越大。

#### 4.1.2 libc管理用户态内存（malloc与free）：

用户态通过malloc与free申请释放内存是通过libc来管理的内存，libc再对接buddy系统。

#### 4.1.3 内核中常见申请内存API

![image-20210404164103940](C:\Users\sparkhuang\AppData\Roaming\Typora\typora-user-images\image-20210404164103940.png)

当使用kmalloc申请内存时，内存一定在低端内存区，并且虚拟地址与物理地址之间转换关系可以直接使用phys_to_virt和virt_to_phys。kmalloc底下通过slab向buddy申请内存，由于是低端内存，内核开机启动就已经做了线性映射，所以kmalloc不需要重新做虚拟内存到物理内存的映射，也就无需重新创建页表。

当使用vmalloc申请内存时，首先从vmalloc区找一片空闲的虚拟地址，然后再从buddy中找到空闲物理地址，最后做虚拟地址到物理地址的映射关系。

ioremap也是映射到vmalloc虚拟内存区的，但是ioremap针对的是寄存器，底下不会走到buddy系统申请物理内存，只是将虚拟地址与物理地址建立映射，方便内核通过虚拟地址访问物理地址。

需要理解被映射与被申请不是同一个概念，Linux内核一开机就将低端内存映射到虚拟地址空间，但是并不是所有的低端内存都被内核用掉，在buddy系统中仍旧有部分是空闲的。内核需要拿内存时也还是找buddy系统申请。所以说，低端内存一开机就被Linux内存做了映射，但并没有说低端内存就被Linux用掉了，只是做了映射，低端内存可以被任何人用，可以被kmalloc使用，可以被vmalloc使用，也可以被用户态的malloc使用。

总结一下，kmalloc申请内存是因为开机就映射好了，所以可以直接拿到；vmalloc申请内存开机没映射好，所以需要重新建立映射创建页表。而ioremap直接在vmalloc区中找一块虚拟地址，然后将物理地址与虚拟地址建立映射关系，无物理内存申请。

关于vmalloc区虚拟内存，可以去查看`cat /proc/vmallocinfo`，里面存在两部分映射：

- ioremap式的寄存器映射，不存在物理内存的分配
- vmalloc申请的内存，需要从buddy系统中申请物理内存，粒度为一页。

#### 4.1.4 用户态malloc中的VSS与RSS

上面提到的内核态kmalloc与vmalloc申请内存会立马得到物理内存，但是应用程序申请内存时并不会立即拿到物理内存。比如`int * p = malloc(100M)`：

- 在用户态的虚拟地址空间找一块100M的连续虚拟地址空间。
- Linux对该段虚拟地址创建一个vma，并设置权限为R+W。
- 然后将该段虚拟地址映射到zero page（零页物理地址），所有的虚拟地址的页表都映射到零页物理地址，内核在初始化时创建一个物理页并清零，称为0页。所以此时并未拿到物理地址，只是映射到物理0页，此时物理0页对应的页表都是R（只读）。此时可以读，并且读到的数据都是0。
- 当应用程序对该段申请的虚拟地址进行写时，由于页表中只有读权限，没有写权限，所以mmu会给CPU发送缺页中断pagefault，内核处理pagefault时，能从寄存器中读到发生pagefault的原因和地址，首先判读地址是否合法，然后再看产生pagefault的原因，发现是写操作，此时页表并没有写的权限，但是VMA中有写的权限，此时Linux不仅不会给进程发送段错误，而且还会给进程从buddy系统中申请一页物理内存，然后将写的虚拟地址映射到申请的物理内存。

整个过程称为demanding page或者lazy allocation。其中vma中的虚拟内存地址块称为VSS，而申请到的一页物理内存称为RSS，显然VSS大于等于RSS。vma存在的价值就是：

- 标明该段地址是否合法
- 标明这段地址的期待权限

而页表的中权限是真实权限，真实权限可以与vma中的权限不一致。如果实际访问的权限与vma中的权限一致，则内核不会发送段错误，而是在pagefault处理中申请物理内存。

demanding page或者lazy allocation不止是用于堆内存，对于代码段与栈也是一样。

对于应用程序代码段，比如代码段有16M，内核不会直接申请16M物理内存，然后将16M代码段从硬盘段拷贝到内存中，而是：

- 首先给代码段建立vma
- 然后等执行到某个函数不在内存中时，发生缺页中断
- 在缺页中断中申请物理内存，然后从硬盘中读取代码段到物理内存

#### 4.1.5 物理内存不够导致OOM

由于存在lazy allocation，所以，当用户申请内存时，Linux忽悠说已经分配内存，但实际上只是分配虚拟内存，并未分配物理内存。只有在写内存时才兑现物理内存，那么就存在画大饼兑现不了的情况，此时就会出现物理内存耗尽的情况，出现OOM。

OOM时，Linux系统会选择一个系统中最该死的进程，然后把该进程kill掉，把进程的物理内存释放出来。

每一个进程在进程pid目录下面存在oom_score，记录该进程该死程度分值，一旦Linux出现oom时，就会寻找一个评分最高的进程kill掉。

OOM评分因子：

Linux内核通过`mm/oom_kill.c`中的badness()给每个进程一个oom_score，oom_score取决于：

- 驻留内存、pagetable和swap的使用

采用百分比乘以10：一个使用全部内存的进程得分1000，使用0个字节的进程得0分。

- root用户进程减去30
- oom_score_adj：oom_score会加上oom_score_adj这个值
- oom_adj：oom_score的一个调整系数，乘法级别调整

Android的整个用户态进程工作都是oom驱动，Android中没有直接kill进程的方法，Android会根据前后台进程进行分区，通过将前台重要进程的oom_adj调低，会将不重要的后台进程oom_adj调高，当前台进程使用内存过多时系统选择一个后台不重要的进程kill掉。

在嵌入式系统中，使用的内存都是预先规划好的，如果出现oom应该是内存泄漏导致，一般会使能panic_on_oom，当系统出现oom时，会导致panic触发系统重启。

## 5 用户态进程内存消耗分析

对于一个用户态进程，分析其内存消耗时，只分析用户态空间内存消耗，内核态的内存消耗统一算作内核消耗，不计算用户态进程陷入内核部分的内存消耗为用户态进程的内存消耗，凡是内核消耗的内存不算到任何用户态进程头上。

### 5.1 进程VMA

进程是一个资源封装的单位，在进程中有一个结构体叫task_struct，其中有一个结构体成员叫mm_struct用以描述进程的内存资源。mm_struct里面有一个vm_area_struct的链表，一个vm_area_struct就简称一个VMA，一个进程跑起来后是由一段一段的VMA构成的，每一段VMA就代表一个虚拟地址空间。

![image-20210404232008422](C:\Users\sparkhuang\AppData\Roaming\Typora\typora-user-images\image-20210404232008422.png)

想知道具体的VMA，可以使用pmap命令，可以查看进程ID目录下的maps文件，里面每一行展示一段VMA，pmap显示的与maps文件展示的内容有一一对应关系。如果想看的更具体，可以查看进程ID目录下的smaps文件，每个VMA由多行描述。这些VMA的来源可以是进程本身的数据段，栈，堆，引用的动态链接库的数据段和代码段也会映射到进程的VMA中。

![image-20210404233537870](C:\Users\sparkhuang\AppData\Roaming\Typora\typora-user-images\image-20210404233537870.png)

### 5.2 进程内存消耗的4个概念：VSS、RSS、PSS和USS

进程1044与1045是同一个程序运行的两次结果。1054进程是运行一个cat进程。中间长条为物理内存。

- 图中1是bash的代码段
- 图中2是libc的代码段
- 图中3是进程1044的堆
- 图中4是libc代码段的驻留内存（物理内存消耗）
- 图中5是bash代码段的驻留内存
- 图中6是进程1044的堆的驻留内存

![image-20210404235733065](C:\Users\sparkhuang\AppData\Roaming\Typora\typora-user-images\image-20210404235733065.png)

进程1044的VSS=1 + 2 +3；RSS= 4 + 5 + 6；从图中可以看出，标签4表示libc的代码段被三个进程共享，但是算内存是算在一个进程的头上就不合适。

所以引入新的概念PSS，PSS表示比例化的内存消耗，所以进程1044的比例化内存消耗PSS= 标签4/3 + 标签5/2 + 标签6。

最后再引入一个USS，称为独占且驻留内存消耗。
对于一个系统中需要看内存被如何瓜分掉的，需要看PSS，这能反映系统中进程对物理内存的占用情况。因为如果分析RSS，那么最终算出的各个进程消耗内存之和会大于系统内存，因为存在重复计算问题。

如果查看一个进程有没有内存泄漏呢，直接查看USS即可，因为进程内存泄漏最可能是堆，堆的内存就是独占且驻留的。

介绍一个工具，smem，可以将每个进程的swap，RSS，PSS，USS。

### 5.3 page fault的几种可能性以及major和minor

当MMU给CPU发page fault时，硬件寄存器保存了page fault的地址和page fault的原因。

- 当page fault的地址落在空区域

此时Linux认为进程访问的是一个非法的地址，内核会给进程发段错误信号结束进程。

- 当page fault的地址落在堆区域

第一次读是可以的，映射在zero物理页，但是第一次写时，就会发生page fault，此时内核发现此时页表的权限为R，但是VMA中的权限是R+W。这时Linux内核会分配一页物理内存，同时建立虚拟地址与物理内存的映射关系，修好页表的权限了R+W。

- 当page fault的地址落在代码段

如果在此区域写，则Linux内核处理page fault时，发现地址是合法的，但是权限不合法，此时会给进程发段错误信号终止进程；

如果在此区域执行，发生page fault，地址是合法的，权限也是合法的，Linux内核会申请一页物理内存，修改虚拟地址与物理内存映射关系，修改页表权限，从硬盘中将代码段读到内存中。

![image-20210404233727786](C:\Users\sparkhuang\AppData\Roaming\Typora\typora-user-images\image-20210404233727786.png)

我们看到，当在代码段发生page fault时，会伴随着IO行为，此时的开销会比较大。伴随着IO行为的page fault称为Major page fault；没有伴随着IO行为的page fault称为Minor page fault。无论major还是minor fault都是合法的。

### 5.4 应用程序内存泄漏的界定方法

确定内存泄漏的方法是连续多点采样。

### 5.5 应用程序内存泄漏的检测方法

asan

valgrind

## 6 内存与IO的交互

### 6.1 page cache

page cache：Linux读写文件时，用于缓存文件的逻辑内容，从而加快对磁盘上映像和数据的访问。

Linux读文件逻辑：

- read文件时，首先查看内存是否存在文件缓存
- 如果内存存在，直接read返回，得到文件内容
- 如果不在内存，则在内存中申请一页，再将硬盘中文件一页拷贝到内存，然后read返回得到文件内容。
- 如果read小于一页数据，则Linux会从硬盘拷贝一页到缓存，下次访问直接从缓存访问

Linux写文件逻辑：

- write文件时，首先查看内存是否存在文件缓存
- 存在则直接写在文件缓存中，但是不会直接写入到硬盘，除非是direct IO。并标记写入的文件缓存页面为dirty页面，什么时候文件缓存脏页面写回到磁盘，那是内存管理的机制。
- 如果缓存中没有write位置的文件，则Linux会从硬盘中将写文件位置附件一页数据读入内存中。
- 读入内存后，再执行write操作，并标记该页为脏页，待下次从内存中写入磁盘。

从上面的过程可以看出，内存在文件读写过程中充当文件缓存作用，类似指令cache和数据cache。所以每次访问过一次文件后，下次再访问时就快很多，同时U盘拷贝后，不能立马拔掉U盘，而是要手动退出U盘，因为拷贝的文件数据还在缓存中。

Linux中除了调用read/write可以读写文件外，还可以使用mmap读写文件，mmap读写文件逻辑如下：

- 直接将整个文件缓存映射到用户态空间并返回用户态空间地址
- 然后可以像访问文件指针方式直接读写文件

### 6.2 free命令详解

page cache在Linux中有两种可能性：

- 以文件系统中的文件为背景的cached
- 以裸分区/dev/sdax等为背景的buffers

free命令的输出中，buffers和cached两列都是page cache。其中total = used + free，其中used与free是对buddy系统而言的，used就是从buddy系统中已经分配掉的内存，free就是buddy系统剩余可用的内存。从buddy系统上看，物理内存会被APP申请、kernel申请以及page cache使用；但是从Linux系统层面上看，其中page cache占用的内存是可回收的，因为page cache是缓存硬盘中的文件，如果内存吃紧时，完全可以把之前缓存的page cache清除掉，无非下次访问文件时重新从硬盘将文件缓存到内存中。所以第二行的free就是第一行的free + buffers + cached。而第二行的used就是第一行的used - buffers - cached。

buffers与cached的区别：

- cached：从文件系统去访问的文件，缓存到内存中叫cached

比如/dev/sda1分区中存在文件，然后通过mount方式mount到/mnt/目录，从mnt目录去访问文件导致缓存到内存的缓存就叫cached。

- buffers：直接访问硬盘分区方式，缓存到内存中叫buffers

如果不经过mount，直接使用dd命令对硬盘设备进行读写，此时缓存到内存的缓存就称为buffers。文件系统中的rawdata或者metadata也是buffers，相当于就是文件的具体数据是以页缓存的称为cached。

buffers与cached在Linux都是缓存page cache，只是统计意义上的区别，没有本质区别。

执行`echo 3 > /proc/sys/vm/drop_caches`可以清除可以清除的缓存，但是不一定可以清空缓存。

新版的free命令中buffers和cached合并了，used和free也没有第二行，会增加available字段，available字段并不是准确的系统可获得的内存，而是一个估计值。buffers和cached在`/proc/meminfo`中可以看到，其中Memavailable就是所有的Memfree + 部分的Buffers和部分的Cached。

### 6.3 read、write和mmap

mmap其实就在用户态地址空间创建了一个VMA，然后将这个VMA映射到page cache的物理内存。所以导致mmap看起来像进程的虚拟空间指向了一个文件，但实际上是进程的虚拟地址空间映射到page cache的物理内存，这个page cache就是硬盘中指定文件的page cache。

进程代码段的本质就是mmap进程二进制ELF文件中代码段到用户态地址空间，然后到mmap后的地址上执行，显然这里映射的页表权限是R + X的，所以代码段的本质就是将ELF中代码段的部分cache到缓存中，然后mmap重新映射到用户态地址空间够CPU执行。

所有Linux中代码段的本质就是page cache，lazy demand，而且是reclaim可回收的。

### 6.4 file-backed页面与匿名页

Linux中的内存页面分为两种：

- file-backed页面

file-backed页面把进程的虚拟地址空间映射到files，比如镜像文件的代码段，比如mmap一个字体文件。这类页面是可回收的，下次访问时可以再次缓存。

- anonymous匿名页面

anonymous页面是进程的虚拟地址没有映射到任何文件，比如进程的stack，heap，Cow pages（数据段，写时拷贝）。这类页面是不可回收的。

### 6.5 swap以及swap分区

由于匿名页是不可回收的，当系统可用内存小于所有匿名页时，就会导致内存不够用，因为匿名页需要常驻内存。由于匿名页没有文件背景，此时Linux会将匿名页伪造一个文件背景，这个伪造的文件位于硬盘的swap分区，当系统匿名页过大时就会交换到swap分区中伪造的文件中，这就是Linux中的swap分区。swap作为动词时，表示有文件背景的或者匿名页的交换，但是匿名页往swap分区交换（CONFIG_SWAP开启后）；作为名词时，特制匿名页的交换。

swap在Linux中称为交换分区，但是在Windows就称为虚拟内存（在硬盘中存在），Windows中的PageFile.sys文件就是类似于Linux中的swap分区。

### 6.6 页面回收LRU算法与zRAM

所有的页面回收算法都是LRU算法，即最近最少使用算法，包括CPU内部的cache与内存之间的交换也是LRU算法。这是由局部性原理造成的（时间局部性与控件局部性）。

对于典型的嵌入式系统，很少使用户swap分区：

- 嵌入式的存储介质都很慢，匿名页交换会极大影响性能。
- 一般都是flash，读写寿命有限。

由于swap分区存在缺陷，后来有人提出zRAM，即将物理内存中划分一小部分内存用于交换使用，在这一小部分内存中专门用于交换，且交换的内存数据进来会压缩，出去会解压缩。这样这一小部分的内存就可以容下更多的匿名页，间接的扩大系统内存，即使用CPU的算力换系统内存。所以zRAM在嵌入式系统就很常用了。